{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# StarryNight\n",
    "\n",
    "## Team Members\n",
    "- 902011, Moleri Andrea, a.moleri@campus.unimib.it\n",
    "- 856114, Costantini Davide, d.costantini6@campus.unimib.it\n",
    "- 865939, Armani Filippo, f.armani1@campus.unimib.it\n",
    "\n",
    "## Description of the Reference Domain and Objectives\n",
    "\n",
    "The StarryNight project aims to construct a star classification system utilizing machine learning techniques acquired during the course of the Machine Learning curriculum. The primary objective is to demonstrate that stars adhere to a discernible pattern, specifically referred to as the Hertzsprung-Russell Diagram or HR-Diagram. This diagram serves as the basis for classifying stars by plotting their features, providing valuable insights into their characteristics.\n",
    "\n",
    "## Design Choices for Dataset Creation, Hypotheses, and Assumptions\n",
    "\n",
    "![](../Images/Spectral%20Class%20Diagram.png)\n",
    "\n",
    "In crafting the dataset, we assume that stars exhibit identifiable patterns in their features, allowing for meaningful classification. The HR-Diagram will be employed as the guiding framework for the classification system. The dataset will encompass a range of features crucial for classification:\n",
    "\n",
    "- **Absolute Temperature**: the absolute temperature of a celestial body, denoted by the symbol $T$, is measured in Kelvin $(K)$. It represents the temperature of the body on the Kelvin scale, an absolute temperature scale where $0K$ corresponds to absolute zero, the theoretical lowest temperature possible. Absolute temperature is a fundamental parameter in astrophysics and is crucial for understanding the thermodynamic characteristics of celestial objects.\n",
    "\n",
    "- **Relative Luminosity**: relative luminosity, expressed as $L/L_o$, denotes the ratio of a celestial body's luminosity $(L)$ to the solar luminosity $(L_o)$. Luminosity is the total amount of energy radiated by the object per unit time. This dimensionless quantity provides insights into the intrinsic brightness of a celestial body relative to the Sun, serving as a key metric for comparative stellar analyses.\n",
    "\n",
    "- **Relative Radius**: the relative radius, denoted by $R/R_o$, represents the ratio of a celestial body's radius $(R)$ to the solar radius $(R_o)$. This dimensionless parameter is essential in characterizing the size of celestial bodies, facilitating the comparison of their physical dimensions relative to the Sun, which serves as a standard reference.\n",
    "\n",
    "- **Absolute Magnitude**: absolute magnitude $(M_v)$ is a measure of the intrinsic brightness of a celestial object as it would appear if placed at a standard distance of 10 parsecs from an observer. This parameter is defined on the logarithmic scale, and its determination involves corrections for both distance and interstellar extinction. Absolute magnitude enables astronomers to assess the true luminosity of celestial bodies independent of their varying distances from Earth.\n",
    "\n",
    "- **Star Color**: the term \"Star Color\" refers to the visual perception of a celestial object's hue as observed from Earth. This qualitative characteristic is attributed to the dominant wavelengths emitted by the star's surface. Common colors include white, red, blue, yellow, and yellow-orange. The analysis of star color provides valuable information about the temperature and composition of a star's outer layers.\n",
    "\n",
    "- **Spectral Class**: spectral class categorizes stars based on their spectral characteristics, primarily determined by the temperature of their surfaces. The spectral sequence, from hottest to coolest, is denoted by the letters $O, B, A, F, G, K$, and $M$. This classification system aids astronomers in classifying stars and understanding their fundamental properties, such as temperature, luminosity, and chemical composition.\n",
    "\n",
    "- **Star Type**: star type refers to the broader categorization of celestial objects based on their evolutionary stage and physical characteristics. This classification includes Red Dwarfs, which are low-mass and long-lived stars; Brown Dwarfs, sub-stellar objects not massive enough to sustain nuclear fusion; White Dwarfs, remnants of low to medium-mass stars; Main Sequence stars, like our Sun, undergoing hydrogen fusion; SuperGiants, massive and luminous stars; and HyperGiants, the most massive and intrinsically bright stars in the stellar hierarchy. Understanding star types is crucial for comprehending the diverse life cycles of stars in the cosmos.\n",
    "\n",
    "\n",
    "The designated target for our classification endeavors will be the **Star Type**. The following definitions apply:\n",
    "\n",
    "- $Lo = 3.828 * 10^{26}~Watts$ _(Average Luminosity of the Sun)_\n",
    "- $Ro = 6.9551 * 10^{8}~m$ _(Average Radius of the Sun)_\n",
    "\n",
    "## Data Formatting and Analysis\n",
    "\n",
    "Let's star by running the code snippet below, that is needed in order to import all the necessary dependencies for the project."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42881dfa3452bd68"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Importing the necessary dependencies\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/keras/__init__.py:21\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \n\u001B[1;32m     17\u001B[0m \u001B[38;5;124;03mDetailed documentation and user guides are available at\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;124;03m[keras.io](https://keras.io).\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute\n\u001B[0;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m models\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minput_layer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Input\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msequential\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/keras/models/__init__.py:18\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# ==============================================================================\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Functional\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msequential\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtraining\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/keras/engine/functional.py:24\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mitertools\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtensor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m layout_map \u001B[38;5;28;01mas\u001B[39;00m layout_map_lib\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Importing the necessary dependencies\n",
    "import keras\n",
    "import tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T11:40:38.390408Z",
     "start_time": "2024-01-01T11:40:38.201739Z"
    }
   },
   "id": "83d0769a3a8773e1"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "11537f061b394c55"
  },
  {
   "cell_type": "markdown",
   "source": [
    "What follows is the preliminary formatting of the dataset, that ensures that all the considered instances have correct and well-formatted values. It is also important to make sure that the target column is a categorical data type, which will lead to better performances, not only in operations, but also in training our model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "886ad9aa1cf2944a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-01T11:30:05.828799Z",
     "start_time": "2024-01-01T11:30:05.801934Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Reading the dataset from a CSV file\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarsDataset.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Converting each color to uppercase for consistency, removing leading and \u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# trailing whitespaces, and replacing spaces with hyphens to ensure uniformity\u001B[39;00m\n\u001B[1;32m      6\u001B[0m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStar Color\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m [color\u001B[38;5;241m.\u001B[39mupper()\u001B[38;5;241m.\u001B[39mstrip()\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m color \u001B[38;5;129;01min\u001B[39;00m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStar Color\u001B[39m\u001B[38;5;124m\"\u001B[39m]]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Reading the dataset from a CSV file\n",
    "df = pd.read_csv(\"StarsDataset.csv\")\n",
    "\n",
    "# Converting each color to uppercase for consistency, removing leading and \n",
    "# trailing whitespaces, and replacing spaces with hyphens to ensure uniformity\n",
    "df[\"Star Color\"] = [color.upper().strip().replace(\" \", \"-\") for color in df[\"Star Color\"]]\n",
    "\n",
    "# Converting the \"Star Color\" column to a categorical data type\n",
    "df[\"Star Color\"] = df[\"Star Color\"].astype(\"category\")\n",
    "\n",
    "# Printing the results of our formatting\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Having confirmed the dimensions and main features of the dataframe, our attention is now directed towards understanding the distribution of values within each target class. The upcoming code snippet aims to underline the distribution of the number of instances associated with each target classes. The values within the target classes appear to be evenly distributed, presenting a balanced sampling across the dataset. After this consideration, we will also describe the dataframe for easier reference, including relevant statistical values such as means and percentiles."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d32447d7a57efb6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Visualizing the distribution of the target variable using a pie chart\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m plt\u001B[38;5;241m.\u001B[39mpie(df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStar Type\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalue_counts(), labels\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m3\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m4\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m5\u001B[39m\u001B[38;5;124m\"\u001B[39m], autopct\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%1.1f\u001B[39;00m\u001B[38;5;132;01m%%\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Adding a legend for clarity\u001B[39;00m\n\u001B[1;32m      5\u001B[0m plt\u001B[38;5;241m.\u001B[39mlegend()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualizing the distribution of the target variable using a pie chart\n",
    "plt.pie(df[\"Star Type\"].value_counts(), labels=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], autopct=\"%1.1f%%\")\n",
    "\n",
    "# Adding a legend for clarity\n",
    "plt.legend()\n",
    "\n",
    "# Setting a title for the plot\n",
    "plt.title(\"Distribution of The Target Variable\")\n",
    "\n",
    "# Displaying the pie chart\n",
    "plt.show()\n",
    "\n",
    "# Generating relevant statistics for the dataset\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T11:30:07.012228Z",
     "start_time": "2024-01-01T11:30:07.001353Z"
    }
   },
   "id": "9f054b05d689041"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's begin by visually exploring the dataset through a normalized bar plot, with a focus on the star type as our target variable. Consequently, we will depict all numerical attributes in relation to the star type itself, providing insight into their distribution. It is essential to acknowledge that the numeric values are normalized on a scale between 0 and 1. This normalization ensures visibility, considering the substantial differences in orders of magnitude among the represented values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fcc8377386d705e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (series \u001B[38;5;241m-\u001B[39m series\u001B[38;5;241m.\u001B[39mmin()) \u001B[38;5;241m/\u001B[39m (series\u001B[38;5;241m.\u001B[39mmax() \u001B[38;5;241m-\u001B[39m series\u001B[38;5;241m.\u001B[39mmin())\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Extract unique star types from the \"Star Type\" column\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m starTypes \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStar Type\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39munique()\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Create a temporary DataFrame for normalization\u001B[39;00m\n\u001B[1;32m      9\u001B[0m temp_df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mcopy()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Define a normalization function to scale a series between 0 and 1\n",
    "def normalize(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "# Extract unique star types from the \"Star Type\" column\n",
    "starTypes = df[\"Star Type\"].unique()\n",
    "\n",
    "# Create a temporary DataFrame for normalization\n",
    "temp_df = df.copy()\n",
    "\n",
    "# Normalize selected attributes based on star type\n",
    "temp_df[\"Temperature (K)\"] = temp_df.groupby(\"Star Type\")[\"Temperature (K)\"].transform(normalize)\n",
    "temp_df[\"Luminosity(L/Lo)\"] = temp_df.groupby(\"Star Type\")[\"Luminosity(L/Lo)\"].transform(normalize)\n",
    "temp_df[\"Radius(R/Ro)\"] = temp_df.groupby(\"Star Type\")[\"Radius(R/Ro)\"].transform(normalize)\n",
    "temp_df[\"Absolute Magnitude(Mv)\"] = temp_df.groupby(\"Star Type\")[\"Absolute Magnitude(Mv)\"].transform(normalize)\n",
    "\n",
    "# Calculate mean values for each normalized attribute grouped by star type\n",
    "value_means = {\n",
    "    \"Temperature\": temp_df.groupby(\"Star Type\")[\"Temperature (K)\"].mean(),\n",
    "    \"Luminosity\": temp_df.groupby(\"Star Type\")[\"Luminosity(L/Lo)\"].mean(),\n",
    "    \"Radius\": temp_df.groupby(\"Star Type\")[\"Radius(R/Ro)\"].mean(),\n",
    "    \"Absolute Magnitude\": temp_df.groupby(\"Star Type\")[\"Absolute Magnitude(Mv)\"].mean()\n",
    "}\n",
    "\n",
    "# Plotting the normalized attributes by star type\n",
    "x = np.arange(len(starTypes))\n",
    "width = 0.2\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))  \n",
    "\n",
    "# Iterating through attribute means and plotting bar charts\n",
    "for attribute, measurement in value_means.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "    multiplier += 1\n",
    "\n",
    "# Setting plot labels and formatting\n",
    "ax.set_ylabel('Normalized Values')\n",
    "ax.set_title('Star Attributes by Type')\n",
    "ax.set_xticks(x + width * (multiplier - 1) / 2)\n",
    "ax.set_xticklabels(starTypes)\n",
    "ax.legend(loc='upper left', ncols=3)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Displaying the legend inside the plot for better aesthetics\n",
    "plt.legend(loc='best', bbox_to_anchor=(1.0, 1.0), title='Legend')  \n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T11:30:08.364087Z",
     "start_time": "2024-01-01T11:30:08.327534Z"
    }
   },
   "id": "f062227130a9c13a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following some iterative experimentation, a scatter plot is employed to visually represent a pair of attributes exhibiting linear separability. Specifically, our investigation identifies \"Temperature (K)\" and \"Absolute Magnitude (Mv)\" as the optimal attributes for this purpose within the dataframe. The resultant plot  affirms that there is no necessity for remapping the existing attribute space to a new one, as the selected attributes already effectively capture the desired linear separation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f0a6c325bcc61b1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating a scatter plot using Seaborn\n",
    "ax = sns.scatterplot(\n",
    "    x=df[\"Temperature (K)\"].transform(normalize),\n",
    "    y=df[\"Absolute Magnitude(Mv)\"].transform(normalize),\n",
    "    hue=df[\"Star Type\"],\n",
    "    palette=\"Set1\"\n",
    ")\n",
    "\n",
    "# Setting labels for the x and y axes\n",
    "ax.set(xlabel='Temperature (K)', ylabel='Absolute Magnitude (Mv)')\n",
    "\n",
    "# Adding a title to the plot\n",
    "plt.title('Normalized Temperature vs. Absolute Magnitude by Star Type')\n",
    "\n",
    "# Adding a legend for better interpretation\n",
    "ax.legend(loc='best')\n",
    "\n",
    "# Displaying a grid on the plot for improved readability\n",
    "ax.grid(True)\n",
    "\n",
    "# Displaying the scatter plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-01T11:00:29.499087Z"
    }
   },
   "id": "ccbc68a68a809830"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then move on to Principal Component Analysis, starting with Variance Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e8ec9c6f53b8fc3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Selecting attributes for analysis, assuming the first four columns of the DataFrame\n",
    "attributes = list(df.columns[:4])\n",
    "\n",
    "# Standardizing the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df[attributes])\n",
    "\n",
    "# Applying Principal Component Analysis (PCA) on the scaled data\n",
    "pca = PCA().fit(scaled_data)\n",
    "\n",
    "# Define a list of colors for the bars\n",
    "colors = ['red', 'blue', 'yellow', 'orange']\n",
    "\n",
    "# Plotting the explained variance ratios for each principal component as bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(attributes, pca.explained_variance_ratio_, color=colors, alpha=0.7)\n",
    "\n",
    "# Plotting a line connecting the peaks\n",
    "ax.plot(attributes, pca.explained_variance_ratio_, marker='o', color='black', label='Variance Ratio')\n",
    "\n",
    "# Adding labels and title to the plot\n",
    "plt.xlabel(\"Principal Components\")\n",
    "plt.ylabel(\"Variance Ratio\")\n",
    "plt.title(\"Variance Analysis\")\n",
    "\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "\n",
    "# Adjusting layout to avoid label overlapping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-01T11:00:29.501954Z"
    }
   },
   "id": "f341ef6f6fd8a1e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pcs = pca.components_\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.set_xlim([-1, 1])\n",
    "ax.set_ylim([-1, 1])\n",
    "\n",
    "for i, (x, y) in enumerate(zip(pcs[0, :], pcs[1, :])):\n",
    "    # plot arrows from origin to (x, y)\n",
    "    ax.quiver(0, 0, x, y, angles='xy', scale_units='xy', scale=1, color=plt.cm.Set1(i/len(pcs[0])), alpha=0.8)\n",
    "\n",
    "    # display the label of the point\n",
    "    ax.text(x, y, df.columns[i], fontsize='10')\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_title(\"Principal Component Analysis\")\n",
    "\n",
    "# Add grid\n",
    "ax.grid(True)\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-01T11:00:29.506883Z"
    }
   },
   "id": "9411812af5b3c4f4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Variance Analysis Considerations \n",
    "- **Temperature $(K)$:** a Variance Ratio of approximately $0.6$ indicates a moderate variance compared to the reference population. This may suggest that stellar temperatures in the dataset are relatively homogeneous, but there are still significant differences.\n",
    "- **Luminosity $(L/Lo)$:** a Variance Ratio of approximately $0.2$ indicates lower variance compared to temperatures, but it is still present. The luminosities of stars in the dataset appear to be more homogeneous compared to temperatures.\n",
    "- **Radius $(R/Ro)$:** a Variance Ratio of about $0.1$ suggests low variance compared to the reference population for stellar radius. This may indicate that the radius of stars in the dataset are relatively similar to each other.\n",
    "- **Absolute Magnitude $(Mv)$:** a Variance Ratio of approximately $0.05$ indicates very low variance compared to the reference population for absolute magnitude. This suggests that absolute magnitudes of stars in the dataset are very similar to each other.\n",
    "\n",
    "In light of these considerations, it is our judgment that a reduction in the dataset's dimensionality is unwarranted. The numeric attributes currently at our disposal demonstrate adequate descriptiveness and non-redundancy in portraying the characteristics of the target class. Consequently, a decision has been reached to avoid the implementation of principal component analysis in this instance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbdae9e7f14d155b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creation of train and test sets\n",
    "Let's begin by dividing the Dataset into two categories: train and test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7127583cb0617dba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Renaming the 'Star Type' column to 'target' for clarity\n",
    "df.rename(columns={'Star Type': 'target'}, inplace=True)\n",
    "\n",
    "# Defining the feature columns for model training and testing\n",
    "feature_columns = [\"Temperature (K)\", \"Luminosity(L/Lo)\", \"Radius(R/Ro)\", \"Absolute Magnitude(Mv)\"]\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[feature_columns], df[\"target\"], test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-01T11:00:29.512932Z"
    }
   },
   "id": "f0109803750e0333"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's also standardize the features in the dataframe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74e0b8101d04321b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initializing a StandardScaler object for feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scaling the feature columns in the training set\n",
    "X_train[feature_columns] = scaler.fit_transform(X_train[feature_columns])\n",
    "\n",
    "# Scaling the feature columns in the testing set using the parameters from the training set\n",
    "X_test[feature_columns] = scaler.transform(X_test[feature_columns])\n",
    "\n",
    "# Displaying descriptive statistics for the scaled training set\n",
    "X_train.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-01T11:00:29.521236Z"
    }
   },
   "id": "89a7e577a66cef85"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First Approach: Decision Trees\n",
    "#### *TODO: Add Decision Tree Process*"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b818dc288718b8b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Second Approach: Neural Networks\n",
    "Our decision to employ a Neural Network Model for stellar classification is motivated by several factors. First of all, the capability of neural networks allows them to autonomously recognize patterns in data, a crucial aspect when dealing with the structures present in stellar datasets. Furthermore, the adaptability of neural networks to diverse data types proves advantageous in handling the variability of attributes present in the dataset. We believe the model can recognize patterns more accurately compared to simpler models.\n",
    "\n",
    "One of the most relevant features is the generalization capability of a well-trained neural network, that will enable accurate predictions for stars not present in the training set, provided they share similarities with the training dataset. This may prove its usefulness, as astronomical data constantly expands over time. Moreover, the scalability of neural models with increased data volume further enhances their performance, making them particularly advantageous when access to larger datasets becomes available. In other words, if more data becomes available in the future, given a similar formatting, the model will still be able to both improve and maintain a good level of precision.\n",
    "\n",
    "### Implementation of One-Hot Encoded Format for Standardized Categorical Representation in Neural Network Training\n",
    "The code block below serves the purpose of converting class labels into categorical format. In this particular context, the Keras library is employed for its ease in implementing neural networks, while the Scikit-learn library is reserved for basic machine learning models. The Keras utility function `to_categorical` is utilized for transforming class labels into a one-hot encoded representation. This encoding ensures a standardized format for categorical data, especially beneficial for neural network training. Each class label is mapped to a one-hot vector. This transformation is essential in the context of machine learning, specifically for tasks involving classification, as it facilitates effective model interpretation and learning."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "102bdc414fb9c19c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# The following code utilizes the Keras library to convert the target labels of the training and testing datasets into one-hot encoded format.\n",
    "\n",
    "# Transforming the training labels into one-hot encoded vectors using the to_categorical function from Keras utils.\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "\n",
    "# Transforming the testing labels into one-hot encoded vectors using the to_categorical function from Keras utils.\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-01T11:00:29.526394Z"
    }
   },
   "id": "f212f46f7a20b7c9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Defining input components\n",
    "components = [0, 1, 0]\n",
    "\n",
    "# Creating a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Adding a dense layer with 3 neurons, using ReLU activation function, and specifying input shape (4 features)\n",
    "model.add(Dense(3, input_shape=(4,), activation='relu'))\n",
    "\n",
    "# Adding another dense layer with 3 neurons and softmax activation function\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compiling the model with categorical crossentropy loss, Adam optimizer, and accuracy as the metric\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Visualizing the model architecture with input shapes\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-01T11:00:29.534917Z"
    }
   },
   "id": "736c3de8bccd5b34",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5a23a3967677a998"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dd2e93a41bab5246"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
